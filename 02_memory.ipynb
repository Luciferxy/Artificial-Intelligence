{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 2: Memory & State\n",
                "\n",
                "In this module, we will learn how to add **memory** to our chains. \n",
                "By default, LLMs are **stateless** â€” they don't remember previous interactions. To build a chatbot, we need to manage the conversation history.\n",
                "\n",
                "We will cover:\n",
                "1.  **ChatPromptTemplate**: Structured prompts for chat.\n",
                "2.  **MessagesPlaceholder**: A slot to insert chat history.\n",
                "3.  **RunnableWithMessageHistory**: The LCEL way to manage state."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from langchain_groq import ChatGroq\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ChatPrompts & History Slot\n",
                "Instead of a single string, chat models take a list of messages (System, Human, AI).\n",
                "We need a place to store the growing list of past messages. We use `MessagesPlaceholder` for this."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
                "\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", \"You are a helpful assistant.\"),\n",
                "        MessagesPlaceholder(variable_name=\"history\"),  # This is where memory goes\n",
                "        (\"human\", \"{input}\"),\n",
                "    ]\n",
                ")\n",
                "\n",
                "chain = prompt | llm"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Managing History (The 'Store')\n",
                "We need a way to store chat history for different sessions. For this tutorial, we'll use a simple in-memory dictionary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
                "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
                "\n",
                "# Dictionary to store history for each session_id\n",
                "store = {}\n",
                "\n",
                "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
                "    if session_id not in store:\n",
                "        store[session_id] = InMemoryChatMessageHistory()\n",
                "    return store[session_id]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Creating the Stateful Chain\n",
                "Now we wrap our basic chain with `RunnableWithMessageHistory`. This automatically handles:\n",
                "1.  Fetching history from the store using `session_id`.\n",
                "2.  Injecting it into the `history` placeholder.\n",
                "3.  Updating the store with the new Human and AI messages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "with_message_history = RunnableWithMessageHistory(\n",
                "    chain,\n",
                "    get_session_history,\n",
                "    input_messages_key=\"input\",\n",
                "    history_messages_key=\"history\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Testing the Chatbot\n",
                "Let's have a conversation! We must pass a `session_id` in the `config`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "AI: Nice to meet you, Lucifer. That's an... interesting name. Are you referring to the fallen angel from mythology and literature, or perhaps it's just a coincidence? Either way, I'm here to help you with any questions or topics you'd like to discuss. What brings you here today?\n"
                    ]
                }
            ],
            "source": [
                "config = {\"configurable\": {\"session_id\": \"user_1\"}}\n",
                "\n",
                "response1 = with_message_history.invoke(\n",
                "    {\"input\": \"Hi, my name is Lucifer.\"}, \n",
                "    config=config\n",
                ")\n",
                "print(\"AI:\", response1.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "AI: Your name is Lucifer.\n"
                    ]
                }
            ],
            "source": [
                "# Follow up question - does it remember my name?\n",
                "response2 = with_message_history.invoke(\n",
                "    {\"input\": \"What is my name?\"}, \n",
                "    config=config\n",
                ")\n",
                "print(\"AI:\", response2.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Different Session\n",
                "If we change the `session_id`, it shouldn't remember Alice."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "AI (User 2): I don't have any information about your name. This is the beginning of our conversation, and I don't retain any data about individual users. If you'd like to share your name, I'm happy to use it in our conversation.\n"
                    ]
                }
            ],
            "source": [
                "config2 = {\"configurable\": {\"session_id\": \"user_2\"}}\n",
                "\n",
                "response3 = with_message_history.invoke(\n",
                "    {\"input\": \"What is my name?\"}, \n",
                "    config=config2\n",
                ")\n",
                "print(\"AI (User 2):\", response3.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise\n",
                "Create a chatbot that pretends to be a pirate.\n",
                "1.  Modify the `SystemMessage` in the prompt.\n",
                "2.  Chat with it and verify it remembers context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your pirate bot code here\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
