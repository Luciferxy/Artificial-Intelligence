{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 1: LangChain Foundations\n",
                "\n",
                "Welcome to the first notebook of the LangChain learning series! In this module, we will cover:\n",
                "1.  **Environment Setup**: Loading API keys.\n",
                "2.  **LLM Interaction**: How to call a Large Language Model.\n",
                "3.  **Prompt Templates**: Creating reusable prompts.\n",
                "4.  **Simple Chains**: Combining prompts and models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Environment Setup\n",
                "# We need to load our API keys from a .env file.\n",
                "# Make sure you have a file named .env in this directory with your GROQ_API_KEY=...\n",
                "\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# Check if key is loaded (optional, just for verification)\n",
                "if os.getenv(\"GROQ_API_KEY\"):\n",
                "    print(\"Groq API Key loaded successfully.\")\n",
                "else:\n",
                "    print(\"Warning: Groq API Key not found. Please check your .env file.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Basic LLM Interaction\n",
                "LangChain supports many LLM providers (OpenAI, Anthropic, HuggingFace, etc.). We'll use **Groq** for these examples as it is fast and free for developers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import the ChatGroq model\n",
                "from langchain_groq import ChatGroq\n",
                "\n",
                "# Initialize the model\n",
                "# temperature=0 means deterministic outputs (good for learning/coding)\n",
                "# temperature=0.7 is more creative\n",
                "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
                "\n",
                "# Simple invocation\n",
                "response = llm.invoke(\"Hello, how are you?\")\n",
                "print(response.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prompt Templates\n",
                "Hardcoding strings is not scalable. PromptTemplates allow you to create dynamic prompts with variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import PromptTemplate\n",
                "\n",
                "# Create a template string with a variable {topic}\n",
                "template_string = \"Tell me a joke about {topic}.\"\n",
                "\n",
                "prompt_template = PromptTemplate.from_template(template_string)\n",
                "\n",
                "# Use the template to generate a prompt\n",
                "formatted_prompt = prompt_template.invoke({\"topic\": \"cats\"})\n",
                "print(\"Formatted Prompt:\", formatted_prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Simple Chains (LCEL)\n",
                "Modern LangChain uses **LCEL (LangChain Expression Language)** to chain components together using the pipe `|` operator.\n",
                "A basic chain looks like: `Prompt | LLM`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the chain\n",
                "chain = prompt_template | llm\n",
                "\n",
                "# Invoke the chain\n",
                "response = chain.invoke({\"topic\": \"programming\"})\n",
                "\n",
                "print(response.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Output Parsers\n",
                "Often you want the output as a string, not a Message object. We can add a `StrOutputParser`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "output_parser = StrOutputParser()\n",
                "\n",
                "# Update chain: Prompt -> LLM -> OutputParser\n",
                "chain = prompt_template | llm | output_parser\n",
                "\n",
                "final_response = chain.invoke({\"topic\": \"artificial intelligence\"})\n",
                "print(final_response)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise\n",
                "Try creating a chain that:\n",
                "1. Takes a `country` as input.\n",
                "2. Asks for the capital of that country.\n",
                "3. Returns just the name of the capital."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Your code here\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}